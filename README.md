# Emotion Analysis Benchmarking on ISEAR Dataset  

## ğŸ” Project Overview  
This repository contains scripts and experiments for **fine-tuning and benchmarking language models** on **emotion analysis tasks** using the **ISEAR dataset**. The project focuses on comparing the performance of small and large language models in understanding emotional expressions.  

### Goals  
- Benchmark small and large language models on **ISEAR** emotion classification tasks.  
- Fine-tune models to improve accuracy on **emotion analysis** in the **financial news domain**.  
- Develop methods to **fuse financial sentiment analysis** with **emotion recognition** in articles and comments.  

## ğŸ“Œ Dataset  
- **ISEAR Dataset**: International Survey on Emotion Antecedents and Reactions.    

## ğŸ”§ Models  
- Small-scale language models (e.g., DistilBERT, TinyBERT).  
- Large-scale language models (e.g., BERT, RoBERTa, GPT-based).  

## ğŸ“Š Benchmark Metrics  
- Accuracy  
- F1 Score  
- Computational Efficiency  
- Model Size vs. Performance Trade-off  

## ğŸš€ Roadmap  
- [x] Data Preprocessing  
- [x] Baseline Model Training  
- [x] Small vs. Large Model Comparison  
- [ ] Domain Adaptation for Financial News  
- [ ] Final Evaluation & Report  

---

### Always Learning! ğŸ“š  
Contributions, suggestions, and collaborations are welcome!  

# Emotion Analysis Benchmarking on ISEAR Dataset  

## 🔍 Project Overview  
This repository contains scripts and experiments for **fine-tuning and benchmarking language models** on **emotion analysis tasks** using the **ISEAR dataset**. The project focuses on comparing the performance of small and large language models in understanding emotional expressions.  

### Goals  
- Benchmark small and large language models on **ISEAR** emotion classification tasks.  
- Fine-tune models to improve accuracy on **emotion analysis** in the **financial news domain**.  
- Develop methods to **fuse financial sentiment analysis** with **emotion recognition** in articles and comments.  

## 📌 Dataset  
- **ISEAR Dataset**: International Survey on Emotion Antecedents and Reactions.    

## 🔧 Models  
- Small-scale language models (e.g., DistilBERT, TinyBERT).  
- Large-scale language models (e.g., BERT, RoBERTa, GPT-based).  

## 📊 Benchmark Metrics  
- Accuracy  
- F1 Score  
- Computational Efficiency  
- Model Size vs. Performance Trade-off  

## 🚀 Roadmap  
- [x] Data Preprocessing  
- [x] Baseline Model Training  
- [x] Small vs. Large Model Comparison  
- [ ] Domain Adaptation for Financial News  
- [ ] Final Evaluation & Report  

---

### Always Learning! 📚  
Contributions, suggestions, and collaborations are welcome!  
